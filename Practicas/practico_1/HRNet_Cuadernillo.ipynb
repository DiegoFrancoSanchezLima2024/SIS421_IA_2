{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfa6417",
   "metadata": {},
   "source": [
    "<VSCode.Cell language=\"markdown\">\n",
    "# HRNet — Cuadernillo completo\n",
    "\n",
    "Este cuadernillo explica en profundidad HRNet (High-Resolution Network, 2019). Está pensado para tu presentación y estudio: incluye resumen del paper, explicación de la arquitectura paso a paso, implementaciones didácticas en PyTorch, comparaciones con redes tradicionales, ejemplos prácticos (pose estimation y segmentación), visualizaciones y guía para fine-tuning.\n",
    "\n",
    "Índice dinámico (usar las cabeceras de las celdas para navegar):\n",
    "\n",
    "1. Import Required Libraries\n",
    "2. HRNet Architecture Overview\n",
    "3. High-Resolution Representation Maintenance (demo)\n",
    "4. Multi-Resolution Parallel Convolutions\n",
    "5. Multi-Scale Fusion Modules\n",
    "6. HRNet Implementation from Scratch\n",
    "7. Comparison with Traditional CNN Architectures\n",
    "8. HRNet for Human Pose Estimation\n",
    "9. HRNet for Semantic Segmentation\n",
    "10. Performance Benchmarking\n",
    "11. Visualization of Feature Maps\n",
    "12. Transfer Learning with Pre-trained HRNet\n",
    "\n",
    "---\n",
    "\n",
    "> Nota: todo el código es ejecutable en CPU; si tienes GPU activada, PyTorch la usará automáticamente.\n",
    "</VSCode.Cell>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "<VSCode.Cell language=\"python\">\n",
    "# 1. Import Required Libraries\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('Device available:', 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "</VSCode.Cell>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b919b",
   "metadata": {},
   "source": [
    "<VSCode.Cell language=\"markdown\">\n",
    "## HRNet Architecture Overview\n",
    "\n",
    "Resumen del paper original (Sun et al., 2019 - \"Deep High-Resolution Representation Learning for Visual Recognition\").\n",
    "\n",
    "- Idea principal: mantener representaciones de alta resolución durante todo el procesamiento. En vez de aplicar una cadena de convoluciones que bajan progresivamente la resolución (como ResNet), HRNet mantiene varias ramas en paralelo a diferentes resoluciones y realiza fusiones repetidas entre ellas.\n",
    "- Dos características clave:\n",
    "  1. Conexiones en paralelo entre flujos de alta a baja resolución.\n",
    "  2. Intercambio repetido de información entre resoluciones (multi-scale fusion).\n",
    "\n",
    "Ventajas: representaciones espaciales más precisas, mejores predicciones para tareas sensibles a la posición (pose estimation, segmentación, face alignment).\n",
    "\n",
    "Referencias: https://arxiv.org/abs/1908.07919\n",
    "</VSCode.Cell>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d948b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "<VSCode.Cell language=\"python\">\n",
    "# Diagrama simplificado de HRNet (usando matplotlib)\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.text(0.05,0.8,'Entrada\\n(High-res)', fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "plt.text(0.05,0.5,'Stem\\nConv', fontsize=10, bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "plt.arrow(0.25,0.7,0.2,0, head_width=0.02)\n",
    "plt.text(0.5,0.8,'Rama alta\\n(res 1x)', fontsize=10, bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "plt.text(0.5,0.6,'Rama baja\\n(res 1/2)', fontsize=10, bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "plt.text(0.5,0.4,'Rama más baja\\n(res 1/4)', fontsize=10, bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "plt.arrow(0.75,0.7,0.15,0, head_width=0.02)\n",
    "plt.text(0.93,0.7,'Fusión\\n(repeated)', fontsize=10)\n",
    "plt.axis('off')\n",
    "plt.title('Esquema simplificado: HRNet mantiene ramas en paralelo y realiza fusiones repetidas')\n",
    "plt.show()\n",
    "\n",
    "# Demo rápido: comparar shapes de un flujo ResNet-like y HRNet-like con tensor aleatorio\n",
    "x = torch.randn(1,3,256,256)\n",
    "# ResNet-like: reduce resolución por 2 dos veces\n",
    "resnet_shapes = []\n",
    "h = x\n",
    "for i in range(3):\n",
    "    resnet_shapes.append(h.shape)\n",
    "    h = F.avg_pool2d(h, kernel_size=2)\n",
    "resnet_shapes.append(h.shape)\n",
    "\n",
    "# HRNet-like: mantener tres ramas a distintas resoluciones sin reducir la rama alta\n",
    "hr_shapes = [x.shape, (1,64,128,128), (1,128,64,64)]\n",
    "\n",
    "print('ResNet-like shapes (downsampling chain):')\n",
    "for s in resnet_shapes:\n",
    "    print(' ', s)\n",
    "print('\\nHRNet-like (parallel branches examples):')\n",
    "for s in hr_shapes:\n",
    "    print(' ', s)\n",
    "</VSCode.Cell>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "<VSCode.Cell language=\"python\">\n",
    "# 4. Multi-Resolution Parallel Convolutions\n",
    "class ParallelBranch(nn.Module):\n",
    "    \"\"\"Una rama simple que procesa una resolución dada.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, blocks=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(blocks):\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            in_channels = out_channels\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# 5. Multi-Scale Fusion Modules\n",
    "class FuseLayer(nn.Module):\n",
    "    \"\"\"Fusiona una lista de características con diferentes resoluciones.\n",
    "    Para subir/ bajar resolución utiliza conv 1x1 + upsample/avg_pool.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels_list, out_channels_list):\n",
    "        super().__init__()\n",
    "        self.num_branches = len(in_channels_list)\n",
    "        # para cada par (i->j) formamos una transformación\n",
    "        self.transforms = nn.ModuleList()\n",
    "        for i in range(self.num_branches):\n",
    "            row = nn.ModuleList()\n",
    "            for j in range(self.num_branches):\n",
    "                if i == j:\n",
    "                    row.append(nn.Identity())\n",
    "                elif i < j:\n",
    "                    # i es más alta resolución que j: downsample (avg pool)\n",
    "                    ops = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels_list[i], out_channels_list[j], kernel_size=1, bias=False),\n",
    "                        nn.BatchNorm2d(out_channels_list[j])\n",
    "                    )\n",
    "                    row.append(ops)\n",
    "                else:\n",
    "                    # i > j: upsample\n",
    "                    ops = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels_list[i], out_channels_list[j], kernel_size=1, bias=False),\n",
    "                        nn.BatchNorm2d(out_channels_list[j])\n",
    "                    )\n",
    "                    row.append(ops)\n",
    "            self.transforms.append(row)\n",
    "\n",
    "    def forward(self, x_list):\n",
    "        # x_list: lista de tensores [B,C,H,W] de distintas resoluciones (res0: alta)\n",
    "        out = []\n",
    "        for j in range(self.num_branches):\n",
    "            y = 0\n",
    "            for i in range(self.num_branches):\n",
    "                xi = x_list[i]\n",
    "                transf = self.transforms[i][j]\n",
    "                if i == j:\n",
    "                    contrib = transf(xi)\n",
    "                elif i < j:\n",
    "                    # bajar resolución: aplicar transf y luego pool\n",
    "                    contrib = transf(xi)\n",
    "                    factor = 2 ** (j - i)\n",
    "                    contrib = F.avg_pool2d(contrib, kernel_size=factor)\n",
    "                else:\n",
    "                    # subir resolución: aplicar transf y luego upsample\n",
    "                    contrib = transf(xi)\n",
    "                    scale = 2 ** (i - j)\n",
    "                    contrib = F.interpolate(contrib, scale_factor=scale, mode='nearest')\n",
    "                y = y + contrib\n",
    "            out.append(F.relu(y))\n",
    "        return out\n",
    "\n",
    "# Prueba rápida de los módulos\n",
    "a = torch.randn(1,32,128,128)\n",
    "b = torch.randn(1,64,64,64)\n",
    "c = torch.randn(1,128,32,32)\n",
    "branches = [ParallelBranch(3,32), ParallelBranch(32,64), ParallelBranch(64,128)]\n",
    "# solo para mostrar forward con las formas de ejemplo\n",
    "x_list = [torch.randn(1,32,128,128), torch.randn(1,64,64,64), torch.randn(1,128,32,32)]\n",
    "fl = FuseLayer([32,64,128],[32,64,128])\n",
    "out = fl(x_list)\n",
    "for o in out:\n",
    "    print('->', o.shape)\n",
    "</VSCode.Cell>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e79447",
   "metadata": {},
   "outputs": [],
   "source": [
    "<VSCode.Cell language=\"python\">\n",
    "# 6. HRNet Implementation from Scratch (simplificado)\n",
    "class SimpleHRNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000, widths=(32,64,128)):\n",
    "        super().__init__()\n",
    "        # Stem: conv inicial\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, widths[0], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(widths[0]),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Branches: una por cada resolución\n",
    "        self.branches = nn.ModuleList()\n",
    "        for i,w in enumerate(widths):\n",
    "            in_ch = widths[0] if i==0 else widths[i]\n",
    "            self.branches.append(ParallelBranch(in_ch, w, blocks=2))\n",
    "        # Fusions repetidas (dos repeticiones para ejemplificar)\n",
    "        self.fuse1 = FuseLayer(widths, widths)\n",
    "        self.fuse2 = FuseLayer(widths, widths)\n",
    "        # Head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(widths[0], num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        # crear entradas para cada rama: la rama 0 es la salida del stem\n",
    "        x_list = [x, F.avg_pool2d(x,2), F.avg_pool2d(F.avg_pool2d(x,2),2)]\n",
    "        # pasar por ramas\n",
    "        x_list = [self.branches[i](x_list[i]) for i in range(len(self.branches))]\n",
    "        # fusión repetida\n",
    "        x_list = self.fuse1(x_list)\n",
    "        x_list = self.fuse2(x_list)\n",
    "        # clasificador tomando la rama de mayor resolución\n",
    "        out = self.head(x_list[0])\n",
    "        return out\n",
    "\n",
    "# prueba rápida\n",
    "model = SimpleHRNet(num_classes=10)\n",
    "input_tensor = torch.randn(2,3,256,256)\n",
    "out = model(input_tensor)\n",
    "print('Output shape:', out.shape)\n",
    "\n",
    "# mostrar número aproximado de parámetros\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print('Params (approx):', n_params)\n",
    "</VSCode.Cell>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed0636",
   "metadata": {},
   "source": [
    "<VSCode.Cell language=\"markdown\">\n",
    "## 7. Comparison with Traditional CNN Architectures\n",
    "\n",
    "Breve comparación conceptual:\n",
    "\n",
    "- ResNet: flujo en serie, baja resolución acumulativa y luego upsampling si es necesario. Bueno para clasificación.\n",
    "- U-Net: encoder-decoder con skip connections; mantiene detalles gracias a skip pero primero reduce resolución.\n",
    "- HRNet: mantiene alta resolución durante todo el camino y agrega ramas de baja resolución en paralelo; intercambia información frecuentemente.\n",
    "\n",
    "Ventaja práctica: mejores predicciones en tareas sensibles a la localización espacial.\n",
    "</VSCode.Cell>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "<VSCode.Cell language=\"python\">\n",
    "# 8. HRNet for Human Pose Estimation (simplificado)\n",
    "class KeypointHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_joints=17):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.out = nn.Conv2d(in_channels, num_joints, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "        return self.out(x)\n",
    "\n",
    "# Prueba con la rama de mayor resolución del HRNet simple\n",
    "model = SimpleHRNet(num_classes=10)\n",
    "with torch.no_grad():\n",
    "    x = torch.randn(1,3,256,256)\n",
    "    # simular obtener la rama de resolución alta desde el forward (rearange)\n",
    "    stem = model.stem(x)\n",
    "    high_res = stem\n",
    "    khead = KeypointHead(high_res.shape[1], num_joints=17)\n",
    "    heatmaps = khead(high_res)\n",
    "    print('Heatmaps shape (B, joints, H, W):', heatmaps.shape)\n",
    "\n",
    "# 9. HRNet for Semantic Segmentation (simplificado)\n",
    "class SegmentationHead(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes=21):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels//2, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels//2)\n",
    "        self.conv2 = nn.Conv2d(in_channels//2, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.interpolate(self.conv2(x), scale_factor=1, mode='bilinear', align_corners=False)\n",
    "        return x\n",
    "\n",
    "seg_head = SegmentationHead(high_res.shape[1], n_classes=21)\n",
    "seg_logits = seg_head(high_res)\n",
    "print('Seg logits shape:', seg_logits.shape)\n",
    "</VSCode.Cell>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5bea6a",
   "metadata": {},
   "source": [
    "<VSCode.Cell language=\"markdown\">\n",
    "## 10. Performance Benchmarking\n",
    "\n",
    "La siguiente celda mide tiempos de forward pase en CPU y en GPU si está disponible. También recoge memoria GPU si es posible.\n",
    "\n",
    "## 11. Visualization of Feature Maps\n",
    "\n",
    "Mostraremos mapas de características intermedios de la rama de alta resolución.\n",
    "\n",
    "## 12. Transfer Learning with Pre-trained HRNet\n",
    "\n",
    "Explicación rápida de cómo cargar pesos desde el model zoo oficial y adaptar la cabeza. El código intentará descargar los pesos, pero en caso de no poder hacerlo, dará instrucciones para que los descargues manualmente.\n",
    "\n",
    "---\n",
    "\n",
    "### Try it\n",
    "\n",
    "Comandos para crear entorno y lanzar el notebook (PowerShell):\n",
    "\n",
    "```powershell\n",
    "python -m venv .venv; .\\.venv\\Scripts\\Activate.ps1\n",
    "pip install --upgrade pip\n",
    "pip install torch torchvision matplotlib seaborn pillow\n",
    "jupyter notebook \"HRNet_Cuadernillo.ipynb\"\n",
    "```\n",
    "</VSCode.Cell>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
